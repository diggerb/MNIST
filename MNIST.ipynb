{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - A Exploration in to Data Analysis\n",
    "\n",
    "This is monologue of my progress through this project.\n",
    "\n",
    "MNIST is the Hello World of neural networks. My aim is to learn as much as possible about neural networks and other data analysis methods by analysing this dataset as well as learning how to best use the features of the high level programming language Python.\n",
    "\n",
    "My approach to this problem will be through the following steps:\n",
    "1. Understand the raw data\n",
    "2. Consider different potential solutions to the problem\n",
    "3. Pick a model\n",
    "4. Process the raw data so it is in a suitable form for the algorithms to work\n",
    "5. Fit/train a model\n",
    "6. Analyse the model and try to find improvements\n",
    "\n",
    "## 1 - Understanding the Raw Data\n",
    "\n",
    "The data are in csv files. Each file has 785 columns. For the training data, the first column is the label, that is the digit drawn by the user. The remaining 784 columns make up the images. The images are 28x28 pixels in size and each row represents one whole image. Consequently each image is of relatively low quality and is in greyscale. The testing data is identical but with the label column omitted, hence there are only 784 columns in this file.\n",
    "\n",
    "The images can be reconstructed by taking the first 28 cells as the first row of pixels of the image. The subsequent 28 cells make up the second row of pixels of the image etc.\n",
    "\n",
    "The submission file must have the following format:\n",
    "```\n",
    "ImageId,Label\n",
    "1,0\n",
    "2,0\n",
    "3,0\n",
    "etc.\n",
    "```\n",
    "\n",
    "## 2 - Potential Solutions\n",
    "\n",
    "One popular solution is to use a neural network to classify the digits. This is something I will explore using Tensorflow on my GPU. If this is successful I may then look to improve this training process with regards to speed and efficiency by training the model in C/C++ on my GPU. \n",
    "\n",
    "This problem would also lend itself well to using some sort of clustering algorithm. Further research and implentation in to k-means clustering algorithms and the algorithms I have learned at university will be considered.\n",
    "\n",
    "A classification regression tree may also work here.\n",
    "\n",
    "Finally I am aware of support-vector machines. I am not entirely sure what these are hence more research is required, but that is another method that should be explored.\n",
    "\n",
    "## 3 - Neural Network Model\n",
    "\n",
    "The neural network model requires an initial layer with one node per pixel. In this case, that is 28^2 input nodes. The output layer requires as many nodes as there are classes. This final layer usually uses a rectified linear unit (ReLU) on each of the nodes. This converts each of the nodes to a value between 0 and 1 such that the sum of all the values sums to 1. This means the output can be interpreted as a probability of the image beloging to each particular class.\n",
    "\n",
    "The difficult part of neural networks is filling in the hidden layers. A single layer is only capable of linear regression. However, deeper networks and other special layers such as convolutional layers allow for a model to pick different features. The aim here is to learn how these layers can be combined to create a good model and this shall be done through hands on experimentation and through researching online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I shall now read the train and test data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "The training data has the following dimensions (42000, 785)\n",
      "The testing data has the following dimensions (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "raw_data_train = pd.read_csv('data/train.csv')\n",
    "raw_data_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(type(raw_data_test))\n",
    "\n",
    "print(raw_data_train.head())\n",
    "\n",
    "print('The training data has the following dimensions', raw_data_train.shape)\n",
    "print('The testing data has the following dimensions', raw_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently the train dataset has 42000 rows and the test dataset has 28000 rows. So there is plenty of data to be working with!\n",
    "\n",
    "First, I need to preprocess the data so it is in a usuable form. The block below coverts the raw data stored as pd.DataFrames and converts it to np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_raw_data(raw_data):\n",
    "    \"\"\"Splits the training data in to training and validation datasets.\n",
    "    \"\"\"\n",
    "    out_y = raw_data.label\n",
    "    x = raw_data.values[:, 1:]\n",
    "    return out_y, reshape_data(x)\n",
    "\n",
    "def reshape_data(array):\n",
    "    \"\"\"Returns n x 28 x 28 numpy array that has been standardised.\n",
    "    \"\"\"\n",
    "    if isinstance(array, pd.DataFrame):\n",
    "        #If array is a pd.DataFrame, assume array is the testing data and convert it to a numpy array\n",
    "        array = array.values[:,:]\n",
    "        \n",
    "    return array.reshape(array.shape[0], 28, 28)/255\n",
    "\n",
    "y_train, x_train = prep_raw_data(raw_data_train)\n",
    "x_test = reshape_data(raw_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
