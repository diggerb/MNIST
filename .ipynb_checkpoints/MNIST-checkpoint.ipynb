{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - A Exploration in to Data Analysis\n",
    "\n",
    "## 1 - Introduction\n",
    "\n",
    "This is monologue of my progress through this project.\n",
    "\n",
    "MNIST is the Hello World of neural networks. My aim is to learn as much as possible about neural networks and other data analysis methods by analysing this dataset as well as learning how to best use the features of the high level programming language Python.\n",
    "\n",
    "My approach to this problem will be through the following steps:\n",
    "1. Understand the raw data\n",
    "2. Consider different potential solutions to the problem\n",
    "3. Pick a model\n",
    "4. Process the raw data so it is in a suitable form for the algorithms to work\n",
    "5. Fit/train a model\n",
    "6. Analyse the model and try to find improvements\n",
    "\n",
    "### 1.1 - Understanding the Raw Data\n",
    "\n",
    "The data are in csv files. Each file has 785 columns. For the training data, the first column is the label, that is the digit drawn by the user. The remaining 784 columns make up the images. The images are 28x28 pixels in size and each row represents one whole image. Consequently each image is of relatively low quality and is in greyscale. The testing data is identical but with the label column omitted, hence there are only 784 columns in this file.\n",
    "\n",
    "The images can be reconstructed by taking the first 28 cells as the first row of pixels of the image. The subsequent 28 cells make up the second row of pixels of the image etc.\n",
    "\n",
    "The submission file must have the following format:\n",
    "```\n",
    "ImageId,Label\n",
    "1,0\n",
    "2,0\n",
    "3,0\n",
    "etc.\n",
    "```\n",
    "\n",
    "### 1.2 - Potential Solutions\n",
    "\n",
    "One popular solution is to use a neural network to classify the digits. This is something I will explore using Tensorflow. If this is successful I may then look to improve this training process with regards to speed and efficiency by training the model in C/C++ on my GPU.\n",
    "\n",
    "This problem would also lend itself well to using some sort of clustering algorithm. Further research and implentation in to k-means clustering algorithms and the algorithms I have learned at university will be considered.\n",
    "\n",
    "A classification regression tree may also work here.\n",
    "\n",
    "Finally I am aware of support-vector machines. I am not entirely sure what these are hence more research is required, but that is another method that should be explored.\n",
    "\n",
    "## 2 - Neural Network Model\n",
    "\n",
    "### 2.0 - Introduction\n",
    "\n",
    "The neural network model requires an initial layer with one node per pixel. In this case, that is 28^2 input nodes. The output layer requires as many nodes as there are classes. This final layer usually uses a softmax activation function on each of the nodes. This converts each of the nodes to a value between 0 and 1 such that the sum of all the values sums to 1. This means the output can be interpreted as a probability of the image beloging to each particular class.\n",
    "\n",
    "The difficult part of neural networks is filling in the hidden layers. A single layer NN is only capable of handling linearly separable classes. Adding extra layers allows for more complex class structure. And nodes without an activation function are only capable of linear regression. Hence different activation functions are used they all behave different during training. Hidden layers will often use the rectified linear unit (ReLU) activation function on each node. This is a very natural interpretation of a neuron. Deeper networks and other special layers, such as convolutional layers, are another method to allow for a model to detect different features. \n",
    "\n",
    "The aim here is to learn how these layers can be combined to create a good model and this shall be done through hands on experimentation and through research.\n",
    "\n",
    "### 2.1 - Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the matplotlib to run well in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # For linear algebra\n",
    "import pandas as pd # For data structures and easy file handling\n",
    "import matplotlib.pyplot as plt # For plotting graphs easily\n",
    "import tensorflow as tf # For neural networks using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I shall now read the train and test data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "Training dimensions (42000, 785)\n",
      "Testing dimensions (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "raw_data_train = pd.read_csv('data/train.csv')\n",
    "raw_data_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(type(raw_data_test))\n",
    "\n",
    "print(raw_data_train.head())\n",
    "\n",
    "print('Training dimensions', raw_data_train.shape)\n",
    "print('Testing dimensions', raw_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently the train dataset has 42000 rows and the test dataset has 28000 rows. So there is plenty of data to be working with!\n",
    "\n",
    "First, I need to preprocess the data so it is in a usuable form. The block below coverts the raw data stored as pd.DataFrames and converts it to np.arrays. This can be thought of as reconstructing the original image. This will be flattened after any convolutional layers (if present) in the neural network model anyway (sending it back to a 1D vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_raw_data(raw_data):\n",
    "    \"\"\"Splits the training data in to training and validation datasets.\n",
    "    \"\"\"\n",
    "    y = raw_data.label.values\n",
    "    out_y = tf.keras.utils.to_categorical(y=y, num_classes=num_classes)\n",
    "    x = raw_data.values[:, 1:]\n",
    "    return out_y, reshape_data(x)\n",
    "\n",
    "def reshape_data(array):\n",
    "    \"\"\"Returns n x 28 x 28 numpy array that has been standardised.\n",
    "    \"\"\"\n",
    "    if isinstance(array, pd.DataFrame):\n",
    "        #assume array is the testing data and convert it to a numpy array\n",
    "        array = array.values[:,:]\n",
    "        \n",
    "    return array.reshape(array.shape[0], 28, 28)/255\n",
    "\n",
    "y_train, x_train = prep_raw_data(raw_data_train)\n",
    "x_test = reshape_data(raw_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show that the preprocessing has worked, here is a plot of a data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train[123])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - First Model\n",
    "\n",
    "Here I shall bulid a model starting with a very basic architecture and try to improve the model iteratively by adding different layer types and combinations.\n",
    "\n",
    "First I will start with a hidden layer with 100 nodes and ReLU as the activation function. To compile to model I will just use stochastic gradient descent (SGD) at first and I shall explore other algorithms some other time. [Click here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) to view the optimiser algorithms built in to TF. These will be explored in depth later. I shall set the loss function to categorical crossentropy. The meaning of this and alternative loss functions are explored in a later section, for now just take this as given. The metric is added to simply show the accuracy during training, it is not required. Other metrics are also explored in a later section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 0.7617 - accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "basic_model_1 = tf.keras.models.Sequential()\n",
    "basic_model_1.add(tf.keras.layers.Flatten())\n",
    "basic_model_1.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
    "basic_model_1.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "basic_model_1.compile(optimizer = 'SGD', \n",
    "                    loss = tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "basic_model_1.fit(x = x_train, y = y_train)\n",
    "\n",
    "predictions_1 = np.argmax(basic_model_1.predict(x = x_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ImageId': range(1,28001), 'Label': predictions_1})\n",
    "output.to_csv('Submissions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to kaggle, this model achieved a 88.5% accuracy! Not bad. However this puts me 2906th of 3180 submissions... that's the 92nd percentile (at the time of writing, June 2020). \n",
    "\n",
    "The next step is to explore methods that will improve the accuracy of results. I should also change the way I check my accuracy of my models as uploading to Kaggle every time is slow.\n",
    "\n",
    "To do this I will split the training data in to a training and validation set. I can hard code this by physically splitting the data or I can use `validation_split = 0.2` to let TF decide which data points should be set aside for validation during the fit. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 0.8623 - accuracy: 0.7868 - val_loss: 0.4619 - val_accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b9bd65668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model_2 = tf.keras.models.Sequential()\n",
    "basic_model_2.add(tf.keras.layers.Flatten())\n",
    "basic_model_2.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
    "basic_model_2.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "basic_model_2.compile(optimizer = 'SGD', \n",
    "                    loss = tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "basic_model_2.fit(x = x_train, \n",
    "                y = y_train,\n",
    "                validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy can now be seen from the output above. This value changes everytime the code is run as different parts of the data are reserved each time for the validation.\n",
    "\n",
    "Now would be a good time to infer each of the output terms above. \n",
    "- `loss:` refers to the loss function defined during compiling. This is a cumulative reading that updates as the model trains. It is not recalculated constantly, just updated with each new piece of information. As such it should not be interpeted as an estimate of the loss of the model but can used to see how the loss function is changing as the model trains. Lower is better and shall explored further in a subsequent section.\n",
    "- `accuracy:` is the proportion of correct classifications by the model. Again, this is a cumulative reading and is not updated each time the model is trained. Hence it is simply used to see how the model accuracy is changing as the model trains.\n",
    "- `val_loss:` is the loss function as above but calculated on the validation set the TF sets aside. This is a good representation of the suitability of the trained model.\n",
    "- `val_accuracy:` refers to the proportion of correct classifications in the validation training set. This is a good estimate of the final model accuracy.\n",
    "\n",
    "### 2.3 - Important Features of Neural Networks\n",
    "\n",
    "Topics that are explored in this section include:\n",
    "- Activation functions\n",
    "- Optimisation Methods\n",
    "- Learning rate\n",
    "- Momentum???\n",
    "- Loss Functions\n",
    "- Epochs\n",
    "- Batch sizes\n",
    "- Node count per layer\n",
    "- Number of layers\n",
    "- Dropout\n",
    "- Different types of layers\n",
    "- Convolutional Layers\n",
    "- Stride length\n",
    "- Data Augmentation (not really applicable here)\n",
    "\n",
    "#### 2.3.1 - Activation Functions\n",
    "\n",
    "There are many different activation functions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
